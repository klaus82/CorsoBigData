{
  "metadata": {
    "name": "Spark_sql_example",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Spark sql example\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Importiamo pyspark e creiamo una sessione"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql import SparkSession\nspark \u003d SparkSession.builder.getOrCreate()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Definiamo il dataframe"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom datetime import datetime, date\nfrom pyspark.sql import Row\ndf \u003d spark.createDataFrame([\n    Row(age\u003d21, salary\u003d2000., name\u003d\u0027Lisa\u0027, dept\u003d\u0027sales\u0027, hire\u003ddate(2019, 1, 1)),\n    Row(age\u003d32, salary\u003d3000., name\u003d\u0027Marco\u0027, dept\u003d\u0027engineering\u0027, hire\u003ddate(2010, 2, 1)),\n    Row(age\u003d44, salary\u003d5000., name\u003d\u0027Andrea\u0027, dept\u003d\u0027ceo\u0027, hire\u003ddate(2000, 3, 1))\n])"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Verifichiamo lo schema del dataframe"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf.printSchema()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Selezioniamo la colonna \"name\""
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\ndf.select(\"name\").show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Cerchiamo tutti i dipendenti che hanno più di 25 anni"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf.filter(df[\u0027age\u0027]\u003e25).show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Utilizziamo una query SQL per cercare nei dati"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf.createOrReplaceTempView(\"people\")\n\nsqlDF \u003d spark.sql(\"SELECT * FROM people where age \u003e 25\")\nsqlDF.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Calcoliamo quante persone hanno la stessa età e quale è\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf.groupBy(\"age\").count().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nsqlDF \u003d spark.sql(\"SELECT age, COUNT(*) as count FROM people group by age\")\nsqlDF.show()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}